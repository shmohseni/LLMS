# **A repository for understanding LLMs**

***

this repository is only gathering resources for LLM topics such as description, architecture, GenAI, RAG and other hot topics. Feel free to contribute and make a useful thing for all.

# **[LLM-Finetuning](https://github.com/ashishpatel26/LLM-Finetuning)**

Welcome to the PEFT (Pretraining-Evaluation Fine-Tuning) project repository! This project focuses on efficiently fine-tuning large language models using LoRA and Hugging Face's transformers library.

![](https://camo.githubusercontent.com/14c39f51b64e2fc3f1ed9da4af3f9027034544551aed3045d7a5930d603e233a/68747470733a2f2f68756767696e67666163652e636f2f64617461736574732f74726c2d696e7465726e616c2d74657374696e672f6578616d706c652d696d616765732f7265736f6c76652f6d61696e2f696d616765732f74726c5f6f766572766965772e706e67)

# **[Generative AI for Beginners](https://github.com/microsoft/generative-ai-for-beginners)**

Learn the fundamentals of building Generative AI applications with our 18-lesson comprehensive course by Microsoft Cloud Advocates.

# **[Transformers-Tutorials](https://github.com/NielsRogge/Transformers-Tutorials)**

This repository contains demos that Niels Rogge maded with the Transformers library by HuggingFace.

# **[Hugging Face Course](https://huggingface.co/learn/nlp-course/chapter1/1)**

This course is designed by Hugging Face for every one that concerns about transformers.

## **[Chat Template](https://huggingface.co/blog/chat-templates)**

Chat models have been trained with very different formats for converting conversations into a single tokenizable string. This post illustrate this process in a good way.

# **[Jay Alammar Blog](https://jalammar.github.io/)**

Jay Alammar's blog is a great source for who that want to understanding LLMs in both theorical and practical way.

# **[LLM University](https://docs.cohere.com/docs/llmu)**

The course covers LLMs starting from the basics, all the way to building and using text representation and text generation models. Its theoretical portion is explained clearly and with analogies and examples rather than formulas, and its practical portion contains lots of useful code examples that will help you solidify your knowledge. It is a one-size-fits-all approach, and learners can pick their own path. For this reason, it is geared for anyone excited about NLP, from beginners in ML, any developer looking to build apps with language AI as well as advanced learners who are ready to put their skills into practice. The course has the following topics, which all serve as starting points depending on your previous knowledge and your goals.

# **[Transformers](https://github.com/huggingface/transformers)**

State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX

# **[LLM Course by Maxime Labonne](https://github.com/mlabonne/llm-course)**

Course to get into Large Language Models (LLMs) with roadmaps and Colab notebooks.

********
